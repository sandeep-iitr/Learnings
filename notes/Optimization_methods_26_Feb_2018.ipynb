{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gradient Descent\n",
    "- Follow the gradient\n",
    "- We make sure where we end up, the function value is decreased.\n",
    "- We don't take into account the: Curvature\n",
    "  - How fast the gradient change is happening, there comes the second derivative: Newton's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step size: \n",
    "- $n_k=\\frac{1}{c+k}$\n",
    "- c is some constant, and k is the iteration number\n",
    "  - $\\sum_{k=1}^{N} n_k$ = +infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the taylor series\n",
    "- $f(\\Theta + \\eta d)$ = $f(\\theta) - \\eta g^{'} g$\n",
    "- Pick step size as:\n",
    "  - $\\eta^{*}=arg_{min} f(\\theta_k + \\eta d)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steepest Descent method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when $d=-g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{d \\theta(n)}{d \\eta} = f(\\theta_k + \\eta d_k)^T d_k$\n",
    "### $f(\\theta_k + \\eta d_k)^T d_k = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Newton's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From second order taylor series expansion around $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $f(\\theta) = f(\\theta_k) + g_k^T (\\theta - \\theta_k) + \\frac{1}{2} (\\theta - \\theta_k)^T H_k (\\theta - \\theta_k)$\n",
    "  - $H_k = \\frac{\\partial^2 f(\\theta)}{\\partial \\theta^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update\n",
    "- $\\theta_{k+1}=\\theta_k - H_k^{-1}g_k$\n",
    "  - $g_k$ is first derivate of $f$ at $\\theta_k$\n",
    "  - $H_k$ is second derivate of $f$ at $\\theta_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "- Computing the Hessian $H_k$ is hard\n",
    "- Inverse of $H_k$ is hard sometimes.\n",
    "  - Compexity of inverting $d*d$ matrix is $d^3$\n",
    "- What if function is non-convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence of $\\theta_k$ to a local minimum\n",
    "$H_k$ has to be semi-positive definite.\n",
    "- or all eigen values of $H_k$ has to be greater than or equal to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed method\n",
    "- Alternate between Newton and Gradient descent in case Hessian is not positive semi-definite.\n",
    "- Once hessian is positive semi-definite, use the Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BFGS: Not computing the exact Hessian\n",
    "## Quasi Newton method\n",
    "   - use an approximate to hessian: rank 2 update to keep estimate the hessian\n",
    "   - from $d^3$ to $d^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Approximations of Hessian that are easy to invert\n",
    "- Rank 2 estimate of the Hessian.\n",
    "  - function of change in gradient and change in $\n",
    "  \\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $Y_k = \\theta_k - \\theta_{k-1}$\n",
    "- $s_k = g_k - g_{k-1}$\n",
    "\n",
    "- $H_k = B_{k+1} = B_k + \\frac{y_k y_k^T}{y_k^T*s_k} - \\frac{(B_k*s_k)(B_ks_k)^T}{s_k^T * B_k *s_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation of Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - $y_i \\in \\{0,1\\}$,\n",
    "### - $P(y_i=1) | x_i \\in R^d$ = $\\frac{1}{1+e^{-W^T x_i}}$\n",
    "- MLE of W: \n",
    "  - $p(Data|W)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
