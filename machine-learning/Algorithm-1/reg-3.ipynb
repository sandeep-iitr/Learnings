{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.951785695971921, 0.669569988269359, 0.170130254933611, 0.623469153884798, 0.925886165117845, 0.81268464284949], [0.51044699898921, 0.922627209918573, 0.0878990164492279, 0.0254153392743319, 0.698443632107228, 0.658544838894159]]\n",
      "['green']\n",
      "['white']\n",
      "[3.70751388051659]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "data_r=[]\n",
    "data_c=[]\n",
    "data_h=[]\n",
    "label_list=[]\n",
    "with open('intern_data.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        #print(row['a'], row['b'],row['c'],row['d'])\n",
    "        \n",
    "        data_r.append([float(row['a']), float(row['b']),float(row['d']),float(row['e']),float(row['f']),float(row['g'])])\n",
    "        data_c.append(row['c'])\n",
    "        data_h.append(row['h'])\n",
    "        label_list.append(float(row['y']))\n",
    "print(data_r[:2])\n",
    "print(data_c[:1])\n",
    "print(data_h[:1])\n",
    "print(label_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Hot encoding C attribute\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['green' 'red' 'yellow' 'green' 'red' 'blue' 'yellow' 'green' 'green'\n",
      " 'green']\n",
      "[1 2 3 1 2 0 3 1 1 1]\n",
      "[[ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Hot encoding H attribute\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['white' 'white' 'black' 'black' 'white' 'white' 'white' 'white' 'white'\n",
      " 'white']\n",
      "[1 1 0 0 1 1 1 1 1 1]\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "values_c = array(data_c)\n",
    "print('-'*100)\n",
    "print('Hot encoding C attribute')\n",
    "print('-'*100)\n",
    "print('-'*100)\n",
    "print(values_c[:10])\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_c = label_encoder.fit_transform(values_c)\n",
    "print(integer_encoded_c[:10])\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "#chaging the shape to a single column from row\n",
    "integer_encoded_c = integer_encoded.reshape(len(integer_encoded_c), 1)\n",
    "\n",
    "onehot_encoded_c = onehot_encoder.fit_transform(integer_encoded_c)\n",
    "print(onehot_encoded_c[:10])\n",
    "#inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "#print(inverted)\n",
    "\n",
    "print('-'*100)\n",
    "\n",
    "\n",
    "values_h = array(data_h)\n",
    "print('-'*100)\n",
    "print('Hot encoding H attribute')\n",
    "print('-'*100)\n",
    "print('-'*100)\n",
    "print(values_h[:10])\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_h = label_encoder.fit_transform(values_h)\n",
    "print(integer_encoded_h[:10])\n",
    "# binary encode\n",
    "\n",
    "#chaging the shape to a single column from row\n",
    "integer_encoded_h = integer_encoded_h.reshape(len(integer_encoded_h), 1)\n",
    "onehot_encoded_h = onehot_encoder.fit_transform(integer_encoded_h)\n",
    "print(onehot_encoded_h[:10])\n",
    "#inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "#print(inverted)\n",
    "\n",
    "print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "[[ 0.9517857   0.66956999  0.17013025  0.62346915  0.92588617  0.81268464\n",
      "   0.          1.          0.          0.          0.          1.        ]\n",
      " [ 0.510447    0.92262721  0.08789902  0.02541534  0.69844363  0.65854484\n",
      "   0.          0.          1.          0.          0.          1.        ]]\n",
      "Label:\n",
      "[ 3.70751388  2.68924256]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_arr=np.array(data_r)\n",
    "#print(data_arr[:2])\n",
    "\n",
    "data = np.concatenate((data_arr,onehot_encoded_c, onehot_encoded_h), axis=1)\n",
    "print('Data:')\n",
    "print(data[:2])\n",
    "label=np.array(label_list)\n",
    "print('Label:')\n",
    "print(label[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [-0.00730915  0.39185073  0.00132106  0.95165108  0.67181686  0.60326591\n",
      " -0.58650175  0.31616989 -0.02141574  0.2917476  -0.31682548  0.31682548]\n",
      "Mean squared error: 0.01\n",
      "Variance score: 0.97\n",
      "----------------------------------------------------------------------------------------------------\n",
      "error = label-pred\n",
      "max: 0.274337165622\n",
      "min: -0.324984624686\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(data, label)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "pred = regr.predict(data)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(label, pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(label, pred))\n",
    "\n",
    "print('-'*100)\n",
    "print('error = label-pred')\n",
    "error= label-pred\n",
    "print('max:',error.max())\n",
    "print('min:',error.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -5.26226645e-03   3.72246144e-01   2.48512891e-04   8.99618321e-01\n",
      "   6.38564236e-01   5.78215512e-01  -5.75092916e-01   3.10365092e-01\n",
      "  -2.33111015e-02   2.88038926e-01  -3.14273631e-01   3.14273631e-01]\n",
      "Mean squared error: 0.01\n",
      "Variance score: 0.97\n",
      "----------------------------------------------------------------------------------------------------\n",
      "error = label-pred\n",
      "max: 0.260411069349\n",
      "min: -0.356536682884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "regr = Ridge(alpha=2.0)\n",
    "# Train the model using the training sets\n",
    "regr.fit(data, label)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "pred = regr.predict(data)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(label, pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(label, pred))\n",
    "\n",
    "print('-'*100)\n",
    "print('error = label-pred')\n",
    "error= label-pred\n",
    "print('max:',error.max())\n",
    "print('min:',error.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.21\n",
      "Variance score: 0.41\n",
      "error = label-pred\n",
      "max: 0.687455039439\n",
      "min: -1.26032760147\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.20\n",
      "Variance score: 0.43\n",
      "error = label-pred\n",
      "max: 0.80025647091\n",
      "min: -1.2424818344\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.19\n",
      "Variance score: 0.46\n",
      "error = label-pred\n",
      "max: 0.802730861759\n",
      "min: -1.22809331599\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.18\n",
      "Variance score: 0.49\n",
      "error = label-pred\n",
      "max: 0.793704165715\n",
      "min: -1.20722833309\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.16\n",
      "Variance score: 0.53\n",
      "error = label-pred\n",
      "max: 0.792161470451\n",
      "min: -1.19262363143\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.15\n",
      "Variance score: 0.58\n",
      "error = label-pred\n",
      "max: 0.781225371909\n",
      "min: -1.179427865\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean squared error: 0.14\n",
      "Variance score: 0.61\n",
      "error = label-pred\n",
      "max: 0.755561351929\n",
      "min: -1.1586631106\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "for degree in [1,2, 3, 4, 5,6,7]:\n",
    "    model = make_pipeline(PolynomialFeatures(degree,include_bias=True), Ridge(alpha=0.1))\n",
    "    model.fit(data_arr, label)\n",
    "    pred = model.predict(data_arr)\n",
    "    # The mean squared error\n",
    "    print('-'*200)\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % mean_squared_error(label, pred))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % r2_score(label, pred))\n",
    "    print('error = label-pred')\n",
    "    error= label-pred\n",
    "    print('max:',error.max())\n",
    "    print('min:',error.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
